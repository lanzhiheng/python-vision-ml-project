#!/usr/bin/env python3
"""
å›¾åƒå‘é‡åŒ–å·¥å…· - æ”¯æŒCPU/GPUæ€§èƒ½å¯¹æ¯”

è¿™ä¸ªè„šæœ¬ä½¿ç”¨é¢„è®­ç»ƒçš„ResNet-152æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œå‘é‡åŒ–ï¼Œ
å¹¶æ”¯æŒCPUå’ŒGPUåˆ‡æ¢ï¼Œä¾¿äºæ€§èƒ½å¯¹æ¯”æµ‹è¯•ã€‚

ä½¿ç”¨æ–¹æ³•:
    python examples/image_vectorizer.py --image_path /path/to/image.jpg --device cpu
    python examples/image_vectorizer.py --image_path /path/to/images/ --device gpu --batch_size 16
"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import os
import argparse
import time
import numpy as np
from typing import Dict, Union, Optional
import sys

class ImageVectorizer:
    """
    å›¾åƒå‘é‡åŒ–å™¨ï¼Œä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹æå–å›¾åƒç‰¹å¾å‘é‡ã€‚
    
    ç‰¹ç‚¹ï¼š
    - ä½¿ç”¨ResNet-152æ·±åº¦æ¨¡å‹ï¼Œè®¡ç®—å¤æ‚åº¦é«˜ï¼Œä¾¿äºå¯¹æ¯”CPU/GPUæ€§èƒ½
    - æ”¯æŒå•å¼ å›¾ç‰‡å’Œæ‰¹é‡å¤„ç†
    - è‡ªåŠ¨è®¾å¤‡æ£€æµ‹å’Œåˆ‡æ¢
    - è¯¦ç»†çš„æ€§èƒ½ç»Ÿè®¡
    """

    def __init__(self, device: str = 'cpu', model_name: str = 'resnet152'):
        """
        åˆå§‹åŒ–å‘é‡åŒ–å™¨ã€‚

        Args:
            device (str): ä½¿ç”¨çš„è®¾å¤‡ ('cpu' æˆ– 'gpu')
            model_name (str): é¢„è®­ç»ƒæ¨¡å‹åç§°
        """
        self.device_name = device
        self.model_name = model_name
        self.model = None
        self.feature_extractor = None
        self.preprocess = None
        self.device = None
        self._setup_model()

    def _setup_model(self):
        """
        åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å¹¶è®¾ç½®é¢„å¤„ç†ç®¡é“ã€‚
        """
        print(f"æ­£åœ¨è®¾ç½®æ¨¡å‹ '{self.model_name}' åœ¨è®¾å¤‡: '{self.device_name}'")
        
        # 1. è®¾ç½®è®¡ç®—è®¾å¤‡
        # 1. è®¾ç½®è®¡ç®—è®¾å¤‡
        if self.device_name in ('gpu', 'cuda') and torch.cuda.is_available():
            self.device = torch.device("cuda")
            print(f"âœ“ CUDA GPUå·²é€‰æ‹©ã€‚ä½¿ç”¨è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"  GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        elif self.device_name == 'mps' and torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("âœ“ Apple Silicon GPU (MPS) å·²é€‰æ‹©")
        else:
            if self.device_name in ('gpu', 'cuda'):
                print("âš ï¸ CUDA GPUä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
            elif self.device_name == 'mps':
                print("âš ï¸ Apple Silicon GPU (MPS) ä¸å¯ç”¨ï¼Œå›é€€åˆ°CPU")
            self.device = torch.device("cpu")
            print("âœ“ ä½¿ç”¨è®¾å¤‡: CPU")

        # 2. åŠ è½½å¼ºå¤§çš„é¢„è®­ç»ƒæ¨¡å‹ (ResNet-152 éå¸¸æ·±ï¼Œè®¡ç®—å¤æ‚)
        print("æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...")
        try:
            if self.model_name == 'resnet152':
                weights = models.ResNet152_Weights.IMAGENET1K_V2
                self.model = models.resnet152(weights=weights)
                print("âœ“ ResNet-152 æ¨¡å‹åŠ è½½å®Œæˆ")
            elif self.model_name == 'resnet101':
                weights = models.ResNet101_Weights.IMAGENET1K_V2
                self.model = models.resnet101(weights=weights)
                print("âœ“ ResNet-101 æ¨¡å‹åŠ è½½å®Œæˆ")
            else:  # é»˜è®¤ä½¿ç”¨ResNet-50
                weights = models.ResNet50_Weights.IMAGENET1K_V2
                self.model = models.resnet50(weights=weights)
                print("âœ“ ResNet-50 æ¨¡å‹åŠ è½½å®Œæˆ")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise

        # 3. ç§»é™¤æœ€åçš„åˆ†ç±»å±‚ï¼Œè·å–ç‰¹å¾å‘é‡
        self.feature_extractor = torch.nn.Sequential(*list(self.model.children())[:-1])
        
        # 4. è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.feature_extractor.eval()
        print("æ­£åœ¨å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¡ç®—è®¾å¤‡...")
        start_time = time.time()
        self.feature_extractor.to(self.device)
        end_time = time.time()
        print(f"âœ“ æ¨¡å‹å·²ç§»åŠ¨åˆ°è®¾å¤‡ (è€—æ—¶: {end_time - start_time:.2f}ç§’)")

        # 5. å®šä¹‰å¤æ‚çš„é¢„å¤„ç†ç®¡é“
        self.preprocess = transforms.Compose([
            transforms.Resize(256),                    # è°ƒæ•´å¤§å°
            transforms.CenterCrop(224),               # ä¸­å¿ƒè£å‰ª
            transforms.ToTensor(),                    # è½¬æ¢ä¸ºå¼ é‡
            transforms.Normalize(                     # æ ‡å‡†åŒ– (ImageNetç»Ÿè®¡)
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225]
            ),
        ])
        print("âœ“ é¢„å¤„ç†ç®¡é“å·²è®¾ç½®")
        
        # è·å–ç‰¹å¾å‘é‡ç»´åº¦
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
            dummy_output = self.feature_extractor(dummy_input)
            self.feature_dim = dummy_output.squeeze().shape[0]
        
        print(f"âœ“ ç‰¹å¾å‘é‡ç»´åº¦: {self.feature_dim}")
        print("=" * 50)

    def vectorize_image(self, image_path: str) -> np.ndarray:
        """
        å¯¹å•å¼ å›¾åƒè¿›è¡Œå‘é‡åŒ–ã€‚

        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„

        Returns:
            np.ndarray: ç‰¹å¾å‘é‡
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶æœªæ‰¾åˆ°: {image_path}")

        try:
            # åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ
            img = Image.open(image_path).convert('RGB')
            img_tensor = self.preprocess(img)
            batch_tensor = torch.unsqueeze(img_tensor, 0).to(self.device)

            # æå–ç‰¹å¾
            with torch.no_grad():
                features = self.feature_extractor(batch_tensor)
            
            # å±•å¹³ä¸ºä¸€ç»´å‘é‡
            vector = features.squeeze().cpu().numpy()
            return vector
            
        except Exception as e:
            print(f"âŒ å¤„ç†å›¾åƒæ—¶å‡ºé”™ {image_path}: {e}")
            raise

    def vectorize_directory(self, dir_path: str, batch_size: int = 8) -> Optional[Dict]:
        """
        æ‰¹é‡å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾åƒã€‚

        Args:
            dir_path (str): å›¾åƒç›®å½•è·¯å¾„
            batch_size (int): æ‰¹å¤„ç†å¤§å°

        Returns:
            dict: åŒ…å«å‘é‡å’Œæ€§èƒ½æŒ‡æ ‡çš„å­—å…¸
        """
        if not os.path.isdir(dir_path):
            raise NotADirectoryError(f"ç›®å½•æœªæ‰¾åˆ°: {dir_path}")

        # æŸ¥æ‰¾æ‰€æœ‰å›¾åƒæ–‡ä»¶
        supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')
        image_files = []
        
        for file in os.listdir(dir_path):
            if file.lower().endswith(supported_formats):
                image_files.append(os.path.join(dir_path, file))
        
        if not image_files:
            print("âŒ ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
            return None

        print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
        print(f"ğŸ”§ æ‰¹å¤„ç†å¤§å°: {batch_size}")
        print("-" * 30)

        all_vectors = {}
        total_time = 0
        processed_count = 0
        failed_count = 0
        
        # æ‰¹é‡å¤„ç†
        for i in range(0, len(image_files), batch_size):
            batch_paths = image_files[i:i+batch_size]
            batch_tensors = []
            valid_paths = []
            
            # é¢„å¤„ç†å½“å‰æ‰¹æ¬¡
            for path in batch_paths:
                try:
                    img = Image.open(path).convert('RGB')
                    img_tensor = self.preprocess(img)
                    batch_tensors.append(img_tensor)
                    valid_paths.append(path)
                except Exception as e:
                    print(f"âš ï¸ è·³è¿‡æŸåçš„å›¾åƒ: {os.path.basename(path)} ({e})")
                    failed_count += 1
                    continue
            
            if not batch_tensors:
                continue
            
            # åˆ›å»ºæ‰¹æ¬¡å¼ é‡å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
            batch_tensor = torch.stack(batch_tensors).to(self.device)
            
            # è®°å½•æ¨ç†æ—¶é—´
            start_time = time.time()
            with torch.no_grad():
                features = self.feature_extractor(batch_tensor)
            
            # åŒæ­¥GPUæ“ä½œ (å¦‚æœä½¿ç”¨GPU)
            if self.device.type == 'cuda':
                torch.cuda.synchronize()
            
            end_time = time.time()
            batch_time = end_time - start_time
            total_time += batch_time
            
            # æå–ç‰¹å¾å‘é‡
            vectors = features.squeeze().cpu().numpy()
            
            # å¤„ç†å•ä¸ªæ ·æœ¬çš„æƒ…å†µ
            if len(valid_paths) == 1:
                vectors = np.expand_dims(vectors, axis=0)

            # ä¿å­˜ç»“æœ
            for j, path in enumerate(valid_paths):
                filename = os.path.basename(path)
                all_vectors[filename] = vectors[j]
                processed_count += 1
            
            # æ˜¾ç¤ºè¿›åº¦
            print(f"ğŸ“Š æ‰¹æ¬¡ {i//batch_size + 1}: {len(valid_paths)} å¼ å›¾åƒï¼Œ"
                  f"è€—æ—¶ {batch_time:.3f}ç§’ "
                  f"(å¹³å‡ {batch_time/len(valid_paths):.3f}ç§’/å¼ )")

        return {
            "vectors": all_vectors,
            "total_time": total_time,
            "processed_count": processed_count,
            "failed_count": failed_count,
            "avg_time_per_image": total_time / processed_count if processed_count > 0 else 0,
            "device": str(self.device),
            "model": self.model_name,
            "feature_dim": self.feature_dim
        }

    def get_device_info(self) -> Dict[str, Union[str, float]]:
        """è·å–è®¾å¤‡ä¿¡æ¯"""
        info = {
            "device_type": self.device.type,
            "device_name": str(self.device)
        }
        
        if self.device.type == 'cuda':
            info.update({
                "gpu_name": torch.cuda.get_device_name(0),
                "gpu_memory_total": torch.cuda.get_device_properties(0).total_memory / 1024**3,
                "gpu_memory_allocated": torch.cuda.memory_allocated(0) / 1024**3,
                "gpu_memory_reserved": torch.cuda.memory_reserved(0) / 1024**3,
            })
        
        return info

def create_test_images(output_dir: str, count: int = 10):
    """
    åˆ›å»ºæµ‹è¯•å›¾åƒæ–‡ä»¶
    
    Args:
        output_dir (str): è¾“å‡ºç›®å½•
        count (int): åˆ›å»ºå›¾åƒæ•°é‡
    """
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"æ­£åœ¨åˆ›å»º {count} å¼ æµ‹è¯•å›¾åƒåˆ° {output_dir}")
    
    for i in range(count):
        # åˆ›å»ºéšæœºå½©è‰²å›¾åƒ
        img_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        img = Image.fromarray(img_array)
        
        # æ·»åŠ ä¸€äº›ç®€å•çš„å‡ ä½•å½¢çŠ¶
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        
        # éšæœºç»˜åˆ¶çŸ©å½¢å’Œåœ†å½¢
        for _ in range(3):
            x1, y1 = np.random.randint(0, 150, 2)
            x2, y2 = x1 + np.random.randint(20, 74), y1 + np.random.randint(20, 74)
            color = tuple(np.random.randint(0, 255, 3))
            
            if np.random.random() > 0.5:
                draw.rectangle([x1, y1, x2, y2], fill=color)
            else:
                draw.ellipse([x1, y1, x2, y2], fill=color)
        
        # ä¿å­˜å›¾åƒ
        img.save(os.path.join(output_dir, f"test_image_{i+1:03d}.jpg"))
    
    print(f"âœ“ å·²åˆ›å»º {count} å¼ æµ‹è¯•å›¾åƒ")

def main():
    parser = argparse.ArgumentParser(
        description="å›¾åƒå‘é‡åŒ–å·¥å…· - æ”¯æŒCPU/GPUæ€§èƒ½å¯¹æ¯”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•å¼ å›¾åƒ (CPU)
  python examples/image_vectorizer.py --image_path image.jpg --device cpu
  
  # æ‰¹é‡å¤„ç†ç›®å½• (GPU)
  python examples/image_vectorizer.py --image_path ./images/ --device gpu --batch_size 16
  
  # åˆ›å»ºæµ‹è¯•å›¾åƒ
  python examples/image_vectorizer.py --create_test_images ./test_images --count 20
  
  # æ€§èƒ½å¯¹æ¯”æµ‹è¯•
  python examples/image_vectorizer.py --image_path ./test_images/ --device cpu --batch_size 8
  python examples/image_vectorizer.py --image_path ./test_images/ --device gpu --batch_size 8
        """
    )
    
    parser.add_argument("--image_path", type=str, 
                       help="å•å¼ å›¾åƒè·¯å¾„æˆ–å›¾åƒç›®å½•è·¯å¾„")
    parser.add_argument("--device", type=str, default="cpu", 
                       help="è®¡ç®—è®¾å¤‡ (ä¾‹å¦‚: cpu, cuda, mps, gpu) (é»˜è®¤: cpu)")
    parser.add_argument("--batch_size", type=int, default=8, 
                       help="æ‰¹å¤„ç†å¤§å° (é»˜è®¤: 8)")
    parser.add_argument("--model", type=str, default="resnet152",
                       choices=["resnet50", "resnet101", "resnet152"],
                       help="ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤: resnet152)")
    parser.add_argument("--create_test_images", type=str,
                       help="åˆ›å»ºæµ‹è¯•å›¾åƒåˆ°æŒ‡å®šç›®å½•")
    parser.add_argument("--count", type=int, default=10,
                       help="åˆ›å»ºæµ‹è¯•å›¾åƒçš„æ•°é‡ (é»˜è®¤: 10)")
    
    args = parser.parse_args()

    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    if args.create_test_images:
        create_test_images(args.create_test_images, args.count)
        return

    # æ£€æŸ¥å‚æ•°
    if not args.image_path:
        parser.print_help()
        return

    try:
        print("ğŸš€ å›¾åƒå‘é‡åŒ–å·¥å…·å¯åŠ¨")
        print("=" * 50)
        
        # åˆå§‹åŒ–å‘é‡åŒ–å™¨
        vectorizer = ImageVectorizer(device=args.device, model_name=args.model)
        
        # æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯
        device_info = vectorizer.get_device_info()
        print("\nğŸ“± è®¾å¤‡ä¿¡æ¯:")
        if device_info["device_type"] == "cuda":
            print(f"  GPU: {device_info['gpu_name']}")
            print(f"  æ€»å†…å­˜: {device_info['gpu_memory_total']:.1f} GB")
        else:
            print(f"  è®¾å¤‡: CPU")

        if os.path.isdir(args.image_path):
            # å¤„ç†ç›®å½•ä¸­çš„å›¾åƒ
            print(f"\nğŸ“‚ æ‰¹é‡å¤„ç†æ¨¡å¼")
            print(f"ç›®å½•è·¯å¾„: {args.image_path}")
            
            results = vectorizer.vectorize_directory(args.image_path, args.batch_size)
            
            if results:
                print("\n" + "=" * 50)
                print("ğŸ‰ å‘é‡åŒ–å®Œæˆ!")
                print("-" * 30)
                print(f"è®¾å¤‡: {results['device']}")
                print(f"æ¨¡å‹: {results['model']}")
                print(f"ç‰¹å¾ç»´åº¦: {results['feature_dim']}")
                print(f"æˆåŠŸå¤„ç†: {results['processed_count']} å¼ å›¾åƒ")
                if results['failed_count'] > 0:
                    print(f"å¤±è´¥: {results['failed_count']} å¼ å›¾åƒ")
                print(f"æ€»è€—æ—¶: {results['total_time']:.3f} ç§’")
                print(f"å¹³å‡æ¯å¼ : {results['avg_time_per_image']:.3f} ç§’")
                print(f"å¤„ç†é€Ÿåº¦: {results['processed_count']/results['total_time']:.2f} å¼ /ç§’")
                
                # æ˜¾ç¤ºç¬¬ä¸€ä¸ªå‘é‡ç¤ºä¾‹
                if results['vectors']:
                    first_image = list(results['vectors'].keys())[0]
                    first_vector = results['vectors'][first_image]
                    print(f"\nğŸ“Š ç¤ºä¾‹ç‰¹å¾å‘é‡ ('{first_image}'):")
                    print(f"  å½¢çŠ¶: {first_vector.shape}")
                    print(f"  å‰10ä¸ªå…ƒç´ : {first_vector[:10]}")
                    print(f"  ç»Ÿè®¡: å‡å€¼={first_vector.mean():.4f}, "
                          f"æ ‡å‡†å·®={first_vector.std():.4f}")

        elif os.path.isfile(args.image_path):
            # å¤„ç†å•å¼ å›¾åƒ
            print(f"\nğŸ–¼ï¸ å•å›¾åƒå¤„ç†æ¨¡å¼")
            print(f"å›¾åƒè·¯å¾„: {args.image_path}")
            
            start_time = time.time()
            vector = vectorizer.vectorize_image(args.image_path)
            end_time = time.time()
            
            processing_time = end_time - start_time
            
            print("\n" + "=" * 50)
            print("ğŸ‰ å‘é‡åŒ–å®Œæˆ!")
            print("-" * 30)
            print(f"è®¾å¤‡: {vectorizer.device}")
            print(f"æ¨¡å‹: {args.model}")
            print(f"å¤„ç†æ—¶é—´: {processing_time:.4f} ç§’")
            print(f"ç‰¹å¾å‘é‡å½¢çŠ¶: {vector.shape}")
            print(f"å‰10ä¸ªå…ƒç´ : {vector[:10]}")
            print(f"ç»Ÿè®¡ä¿¡æ¯: å‡å€¼={vector.mean():.4f}, æ ‡å‡†å·®={vector.std():.4f}")

        else:
            print(f"âŒ é”™è¯¯: è·¯å¾„ '{args.image_path}' ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶æˆ–ç›®å½•")

    except KeyboardInterrupt:
        print("\nâš¡ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()