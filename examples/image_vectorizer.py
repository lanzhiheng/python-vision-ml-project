#!/usr/bin/env python3
"""
ÂõæÂÉèÂêëÈáèÂåñÂ∑•ÂÖ∑ - ÊîØÊåÅCPU/GPUÊÄßËÉΩÂØπÊØî

Ëøô‰∏™ËÑöÊú¨‰ΩøÁî®È¢ÑËÆ≠ÁªÉÁöÑResNet-152Ê®°ÂûãÂØπÂõæÂÉèËøõË°åÂêëÈáèÂåñÔºå
Âπ∂ÊîØÊåÅCPUÂíåGPUÂàáÊç¢Ôºå‰æø‰∫éÊÄßËÉΩÂØπÊØîÊµãËØï„ÄÇ

‰ΩøÁî®ÊñπÊ≥ï:
    python examples/image_vectorizer.py --image_path /path/to/image.jpg --device cpu
    python examples/image_vectorizer.py --image_path /path/to/images/ --device gpu --batch_size 16
"""

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import os
import argparse
import time
import numpy as np
from typing import Dict, Union, Optional
import sys

class ImageVectorizer:
    """
    ÂõæÂÉèÂêëÈáèÂåñÂô®Ôºå‰ΩøÁî®Ê∑±Â∫¶Â≠¶‰π†Ê®°ÂûãÊèêÂèñÂõæÂÉèÁâπÂæÅÂêëÈáè„ÄÇ
    
    ÁâπÁÇπÔºö
    - ‰ΩøÁî®ResNet-152Ê∑±Â∫¶Ê®°ÂûãÔºåËÆ°ÁÆóÂ§çÊùÇÂ∫¶È´òÔºå‰æø‰∫éÂØπÊØîCPU/GPUÊÄßËÉΩ
    - ÊîØÊåÅÂçïÂº†ÂõæÁâáÂíåÊâπÈáèÂ§ÑÁêÜ
    - Ëá™Âä®ËÆæÂ§áÊ£ÄÊµãÂíåÂàáÊç¢
    - ËØ¶ÁªÜÁöÑÊÄßËÉΩÁªüËÆ°
    """

    def __init__(self, device: str = 'cpu', model_name: str = 'resnet152'):
        """
        ÂàùÂßãÂåñÂêëÈáèÂåñÂô®„ÄÇ

        Args:
            device (str): ‰ΩøÁî®ÁöÑËÆæÂ§á ('cpu' Êàñ 'gpu')
            model_name (str): È¢ÑËÆ≠ÁªÉÊ®°ÂûãÂêçÁß∞
        """
        self.device_name = device
        self.model_name = model_name
        self.model = None
        self.feature_extractor = None
        self.preprocess = None
        self.device = None
        self._setup_model()

    def _setup_model(self):
        """
        Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÂπ∂ËÆæÁΩÆÈ¢ÑÂ§ÑÁêÜÁÆ°ÈÅì„ÄÇ
        """
        print(f"Ê≠£Âú®ËÆæÁΩÆÊ®°Âûã '{self.model_name}' Âú®ËÆæÂ§á: '{self.device_name}'")
        
        # 1. ËÆæÁΩÆËÆ°ÁÆóËÆæÂ§á
        # 1. ËÆæÁΩÆËÆ°ÁÆóËÆæÂ§á
        if self.device_name in ('gpu', 'cuda') and torch.cuda.is_available():
            self.device = torch.device("cuda")
            print(f"‚úì CUDA GPUÂ∑≤ÈÄâÊã©„ÄÇ‰ΩøÁî®ËÆæÂ§á: {torch.cuda.get_device_name(0)}")
            print(f"  GPUÂÜÖÂ≠ò: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        elif self.device_name == 'mps' and torch.backends.mps.is_available():
            self.device = torch.device("mps")
            print("‚úì Apple Silicon GPU (MPS) Â∑≤ÈÄâÊã©")
        else:
            if self.device_name in ('gpu', 'cuda'):
                print("‚ö†Ô∏è CUDA GPU‰∏çÂèØÁî®ÔºåÂõûÈÄÄÂà∞CPU")
            elif self.device_name == 'mps':
                print("‚ö†Ô∏è Apple Silicon GPU (MPS) ‰∏çÂèØÁî®ÔºåÂõûÈÄÄÂà∞CPU")
            self.device = torch.device("cpu")
            print("‚úì ‰ΩøÁî®ËÆæÂ§á: CPU")

        # 2. Âä†ËΩΩÂº∫Â§ßÁöÑÈ¢ÑËÆ≠ÁªÉÊ®°Âûã (ResNet-152 ÈùûÂ∏∏Ê∑±ÔºåËÆ°ÁÆóÂ§çÊùÇ)
        print("Ê≠£Âú®Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°Âûã...")
        try:
            if self.model_name == 'resnet152':
                weights = models.ResNet152_Weights.IMAGENET1K_V2
                self.model = models.resnet152(weights=weights)
                print("‚úì ResNet-152 Ê®°ÂûãÂä†ËΩΩÂÆåÊàê")
            elif self.model_name == 'resnet101':
                weights = models.ResNet101_Weights.IMAGENET1K_V2
                self.model = models.resnet101(weights=weights)
                print("‚úì ResNet-101 Ê®°ÂûãÂä†ËΩΩÂÆåÊàê")
            else:  # ÈªòËÆ§‰ΩøÁî®ResNet-50
                weights = models.ResNet50_Weights.IMAGENET1K_V2
                self.model = models.resnet50(weights=weights)
                print("‚úì ResNet-50 Ê®°ÂûãÂä†ËΩΩÂÆåÊàê")
        except Exception as e:
            print(f"‚ùå Ê®°ÂûãÂä†ËΩΩÂ§±Ë¥•: {e}")
            raise

        # 3. ÁßªÈô§ÊúÄÂêéÁöÑÂàÜÁ±ªÂ±ÇÔºåËé∑ÂèñÁâπÂæÅÂêëÈáè
        self.feature_extractor = torch.nn.Sequential(*list(self.model.children())[:-1])
        
        # 4. ËÆæÁΩÆ‰∏∫ËØÑ‰º∞Ê®°ÂºèÂπ∂ÁßªÂä®Âà∞ÊåáÂÆöËÆæÂ§á
        self.feature_extractor.eval()
        print("Ê≠£Âú®Â∞ÜÊ®°ÂûãÁßªÂä®Âà∞ËÆ°ÁÆóËÆæÂ§á...")
        start_time = time.time()
        self.feature_extractor.to(self.device)
        end_time = time.time()
        print(f"‚úì Ê®°ÂûãÂ∑≤ÁßªÂä®Âà∞ËÆæÂ§á (ËÄóÊó∂: {end_time - start_time:.2f}Áßí)")

        # 5. ÂÆö‰πâÂ§çÊùÇÁöÑÈ¢ÑÂ§ÑÁêÜÁÆ°ÈÅì
        self.preprocess = transforms.Compose([
            transforms.Resize(256),                    # Ë∞ÉÊï¥Â§ßÂ∞è
            transforms.CenterCrop(224),               # ‰∏≠ÂøÉË£ÅÂâ™
            transforms.ToTensor(),                    # ËΩ¨Êç¢‰∏∫Âº†Èáè
            transforms.Normalize(                     # Ê†áÂáÜÂåñ (ImageNetÁªüËÆ°)
                mean=[0.485, 0.456, 0.406], 
                std=[0.229, 0.224, 0.225]
            ),
        ])
        print("‚úì È¢ÑÂ§ÑÁêÜÁÆ°ÈÅìÂ∑≤ËÆæÁΩÆ")
        
        # Ëé∑ÂèñÁâπÂæÅÂêëÈáèÁª¥Â∫¶
        with torch.no_grad():
            dummy_input = torch.randn(1, 3, 224, 224).to(self.device)
            dummy_output = self.feature_extractor(dummy_input)
            self.feature_dim = dummy_output.squeeze().shape[0]
        
        print(f"‚úì ÁâπÂæÅÂêëÈáèÁª¥Â∫¶: {self.feature_dim}")
        print("=" * 50)

    def vectorize_image(self, image_path: str) -> np.ndarray:
        """
        ÂØπÂçïÂº†ÂõæÂÉèËøõË°åÂêëÈáèÂåñ„ÄÇ

        Args:
            image_path (str): ÂõæÂÉèÊñá‰ª∂Ë∑ØÂæÑ

        Returns:
            np.ndarray: ÁâπÂæÅÂêëÈáè
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"ÂõæÂÉèÊñá‰ª∂Êú™ÊâæÂà∞: {image_path}")

        try:
            # Âä†ËΩΩÂπ∂È¢ÑÂ§ÑÁêÜÂõæÂÉè
            img = Image.open(image_path).convert('RGB')
            img_tensor = self.preprocess(img)
            batch_tensor = torch.unsqueeze(img_tensor, 0).to(self.device)

            # ÊèêÂèñÁâπÂæÅ
            with torch.no_grad():
                features = self.feature_extractor(batch_tensor)
            
            # Â±ïÂπ≥‰∏∫‰∏ÄÁª¥ÂêëÈáè
            vector = features.squeeze().cpu().numpy()
            return vector
            
        except Exception as e:
            print(f"‚ùå Â§ÑÁêÜÂõæÂÉèÊó∂Âá∫Èîô {image_path}: {e}")
            raise

    def vectorize_directory(self, dir_path: str, batch_size: int = 8) -> Optional[Dict]:
        """
        ÊâπÈáèÂ§ÑÁêÜÁõÆÂΩï‰∏≠ÁöÑÊâÄÊúâÂõæÂÉè„ÄÇ

        Args:
            dir_path (str): ÂõæÂÉèÁõÆÂΩïË∑ØÂæÑ
            batch_size (int): ÊâπÂ§ÑÁêÜÂ§ßÂ∞è

        Returns:
            dict: ÂåÖÂê´ÂêëÈáèÂíåÊÄßËÉΩÊåáÊ†áÁöÑÂ≠óÂÖ∏
        """
        if not os.path.isdir(dir_path):
            raise NotADirectoryError(f"ÁõÆÂΩïÊú™ÊâæÂà∞: {dir_path}")

        # Êü•ÊâæÊâÄÊúâÂõæÂÉèÊñá‰ª∂
        supported_formats = ('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp')
        image_files = []
        
        for file in os.listdir(dir_path):
            if file.lower().endswith(supported_formats):
                image_files.append(os.path.join(dir_path, file))
        
        if not image_files:
            print("‚ùå ÁõÆÂΩï‰∏≠Êú™ÊâæÂà∞ÂõæÂÉèÊñá‰ª∂")
            return None

        print(f"üìÅ ÊâæÂà∞ {len(image_files)} Âº†ÂõæÂÉè")
        print(f"üîß ÊâπÂ§ÑÁêÜÂ§ßÂ∞è: {batch_size}")
        print("-" * 30)

        all_vectors = {}
        total_time = 0
        processed_count = 0
        failed_count = 0
        
        # ÊâπÈáèÂ§ÑÁêÜ
        for i in range(0, len(image_files), batch_size):
            batch_paths = image_files[i:i+batch_size]
            batch_tensors = []
            valid_paths = []
            
            # È¢ÑÂ§ÑÁêÜÂΩìÂâçÊâπÊ¨°
            for path in batch_paths:
                try:
                    img = Image.open(path).convert('RGB')
                    img_tensor = self.preprocess(img)
                    batch_tensors.append(img_tensor)
                    valid_paths.append(path)
                except Exception as e:
                    print(f"‚ö†Ô∏è Ë∑≥ËøáÊçüÂùèÁöÑÂõæÂÉè: {os.path.basename(path)} ({e})")
                    failed_count += 1
                    continue
            
            if not batch_tensors:
                continue
            
            # ÂàõÂª∫ÊâπÊ¨°Âº†ÈáèÂπ∂ÁßªÂä®Âà∞ËÆæÂ§á
            batch_tensor = torch.stack(batch_tensors).to(self.device)
            
            # ËÆ∞ÂΩïÊé®ÁêÜÊó∂Èó¥
            start_time = time.time()
            with torch.no_grad():
                features = self.feature_extractor(batch_tensor)
            
            # ÂêåÊ≠•GPUÊìç‰Ωú (Â¶ÇÊûú‰ΩøÁî®GPU)
            if self.device.type == 'cuda':
                torch.cuda.synchronize()
            
            end_time = time.time()
            batch_time = end_time - start_time
            total_time += batch_time
            
            # ÊèêÂèñÁâπÂæÅÂêëÈáè
            vectors = features.squeeze().cpu().numpy()
            
            # Â§ÑÁêÜÂçï‰∏™Ê†∑Êú¨ÁöÑÊÉÖÂÜµ
            if len(valid_paths) == 1:
                vectors = np.expand_dims(vectors, axis=0)

            # ‰øùÂ≠òÁªìÊûú
            for j, path in enumerate(valid_paths):
                filename = os.path.basename(path)
                all_vectors[filename] = vectors[j]
                processed_count += 1
            
            # ÊòæÁ§∫ËøõÂ∫¶
            print(f"üìä ÊâπÊ¨° {i//batch_size + 1}: {len(valid_paths)} Âº†ÂõæÂÉèÔºå"
                  f"ËÄóÊó∂ {batch_time:.3f}Áßí "
                  f"(Âπ≥Âùá {batch_time/len(valid_paths):.3f}Áßí/Âº†)")

        return {
            "vectors": all_vectors,
            "total_time": total_time,
            "processed_count": processed_count,
            "failed_count": failed_count,
            "avg_time_per_image": total_time / processed_count if processed_count > 0 else 0,
            "device": str(self.device),
            "model": self.model_name,
            "feature_dim": self.feature_dim
        }

    def get_device_info(self) -> Dict[str, Union[str, float]]:
        """Ëé∑ÂèñËÆæÂ§á‰ø°ÊÅØ"""
        info = {
            "device_type": self.device.type,
            "device_name": str(self.device)
        }
        
        if self.device.type == 'cuda':
            info.update({
                "gpu_name": torch.cuda.get_device_name(0),
                "gpu_memory_total": torch.cuda.get_device_properties(0).total_memory / 1024**3,
                "gpu_memory_allocated": torch.cuda.memory_allocated(0) / 1024**3,
                "gpu_memory_reserved": torch.cuda.memory_reserved(0) / 1024**3,
            })
        
        return info

def create_test_images(output_dir: str, count: int = 10):
    """
    ÂàõÂª∫ÊµãËØïÂõæÂÉèÊñá‰ª∂
    
    Args:
        output_dir (str): ËæìÂá∫ÁõÆÂΩï
        count (int): ÂàõÂª∫ÂõæÂÉèÊï∞Èáè
    """
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"Ê≠£Âú®ÂàõÂª∫ {count} Âº†ÊµãËØïÂõæÂÉèÂà∞ {output_dir}")
    
    for i in range(count):
        # ÂàõÂª∫ÈöèÊú∫ÂΩ©Ëâ≤ÂõæÂÉè
        img_array = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)
        img = Image.fromarray(img_array)
        
        # Ê∑ªÂä†‰∏Ä‰∫õÁÆÄÂçïÁöÑÂá†‰ΩïÂΩ¢Áä∂
        from PIL import ImageDraw
        draw = ImageDraw.Draw(img)
        
        # ÈöèÊú∫ÁªòÂà∂Áü©ÂΩ¢ÂíåÂúÜÂΩ¢
        for _ in range(3):
            x1, y1 = np.random.randint(0, 150, 2)
            x2, y2 = x1 + np.random.randint(20, 74), y1 + np.random.randint(20, 74)
            color = tuple(np.random.randint(0, 255, 3))
            
            if np.random.random() > 0.5:
                draw.rectangle([x1, y1, x2, y2], fill=color)
            else:
                draw.ellipse([x1, y1, x2, y2], fill=color)
        
        # ‰øùÂ≠òÂõæÂÉè
        img.save(os.path.join(output_dir, f"test_image_{i+1:03d}.jpg"))
    
    print(f"‚úì Â∑≤ÂàõÂª∫ {count} Âº†ÊµãËØïÂõæÂÉè")

def main():
    parser = argparse.ArgumentParser(
        description="ÂõæÂÉèÂêëÈáèÂåñÂ∑•ÂÖ∑ - ÊîØÊåÅCPU/GPUÊÄßËÉΩÂØπÊØî",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
‰ΩøÁî®Á§∫‰æã:
  # Â§ÑÁêÜÂçïÂº†ÂõæÂÉè (CPU)
  python examples/image_vectorizer.py --image_path image.jpg --device cpu
  
  # ÊâπÈáèÂ§ÑÁêÜÁõÆÂΩï (GPU)
  python examples/image_vectorizer.py --image_path ./images/ --device gpu --batch_size 16
  
  # ÂàõÂª∫ÊµãËØïÂõæÂÉè
  python examples/image_vectorizer.py --create_test_images ./test_images --count 20
  
  # ÊÄßËÉΩÂØπÊØîÊµãËØï
  python examples/image_vectorizer.py --image_path ./test_images/ --device cpu --batch_size 8
  python examples/image_vectorizer.py --image_path ./test_images/ --device gpu --batch_size 8
        """
    )
    
    parser.add_argument("--image_path", type=str, 
                       help="ÂçïÂº†ÂõæÂÉèË∑ØÂæÑÊàñÂõæÂÉèÁõÆÂΩïË∑ØÂæÑ")
    parser.add_argument("--device", type=str, default="cpu", 
                       help="ËÆ°ÁÆóËÆæÂ§á (‰æãÂ¶Ç: cpu, cuda, mps, gpu) (ÈªòËÆ§: cpu)")
    parser.add_argument("--batch_size", type=int, default=8, 
                       help="ÊâπÂ§ÑÁêÜÂ§ßÂ∞è (ÈªòËÆ§: 8)")
    parser.add_argument("--model", type=str, default="resnet152",
                       choices=["resnet50", "resnet101", "resnet152"],
                       help="‰ΩøÁî®ÁöÑÊ®°Âûã (ÈªòËÆ§: resnet152)")
    parser.add_argument("--create_test_images", type=str,
                       help="ÂàõÂª∫ÊµãËØïÂõæÂÉèÂà∞ÊåáÂÆöÁõÆÂΩï")
    parser.add_argument("--count", type=int, default=10,
                       help="ÂàõÂª∫ÊµãËØïÂõæÂÉèÁöÑÊï∞Èáè (ÈªòËÆ§: 10)")
    
    args = parser.parse_args()

    # ÂàõÂª∫ÊµãËØïÂõæÂÉè
    if args.create_test_images:
        create_test_images(args.create_test_images, args.count)
        return

    # Ê£ÄÊü•ÂèÇÊï∞
    if not args.image_path:
        parser.print_help()
        return

    try:
        print("üöÄ ÂõæÂÉèÂêëÈáèÂåñÂ∑•ÂÖ∑ÂêØÂä®")
        print("=" * 50)
        
        # ÂàùÂßãÂåñÂêëÈáèÂåñÂô®
        vectorizer = ImageVectorizer(device=args.device, model_name=args.model)
        
        # ÊòæÁ§∫ËÆæÂ§á‰ø°ÊÅØ
        device_info = vectorizer.get_device_info()
        print("\nüì± ËÆæÂ§á‰ø°ÊÅØ:")
        if device_info["device_type"] == "cuda":
            print(f"  GPU: {device_info['gpu_name']}")
            print(f"  ÊÄªÂÜÖÂ≠ò: {device_info['gpu_memory_total']:.1f} GB")
        else:
            print(f"  ËÆæÂ§á: CPU")

        if os.path.isdir(args.image_path):
            # Â§ÑÁêÜÁõÆÂΩï‰∏≠ÁöÑÂõæÂÉè
            print(f"\nüìÇ ÊâπÈáèÂ§ÑÁêÜÊ®°Âºè")
            print(f"ÁõÆÂΩïË∑ØÂæÑ: {args.image_path}")
            
            results = vectorizer.vectorize_directory(args.image_path, args.batch_size)
            
            if results:
                print("\n" + "=" * 50)
                print("üéâ ÂêëÈáèÂåñÂÆåÊàê!")
                print("-" * 30)
                print(f"ËÆæÂ§á: {results['device']}")
                print(f"Ê®°Âûã: {results['model']}")
                print(f"ÁâπÂæÅÁª¥Â∫¶: {results['feature_dim']}")
                print(f"ÊàêÂäüÂ§ÑÁêÜ: {results['processed_count']} Âº†ÂõæÂÉè")
                if results['failed_count'] > 0:
                    print(f"Â§±Ë¥•: {results['failed_count']} Âº†ÂõæÂÉè")
                print(f"ÊÄªËÄóÊó∂: {results['total_time']:.3f} Áßí")
                print(f"Âπ≥ÂùáÊØèÂº†: {results['avg_time_per_image']:.3f} Áßí")
                print(f"Â§ÑÁêÜÈÄüÂ∫¶: {results['processed_count']/results['total_time']:.2f} Âº†/Áßí")
                
                # ÊòæÁ§∫Á¨¨‰∏Ä‰∏™ÂêëÈáèÁ§∫‰æã
                if results['vectors']:
                    first_image = list(results['vectors'].keys())[0]
                    first_vector = results['vectors'][first_image]
                    print(f"\nüìä Á§∫‰æãÁâπÂæÅÂêëÈáè ('{first_image}'):")
                    print(f"  ÂΩ¢Áä∂: {first_vector.shape}")
                    print(f"  Ââç10‰∏™ÂÖÉÁ¥†: {first_vector[:10]}")
                    print(f"  ÁªüËÆ°: ÂùáÂÄº={first_vector.mean():.4f}, "
                          f"Ê†áÂáÜÂ∑Æ={first_vector.std():.4f}")

        elif os.path.isfile(args.image_path):
            # Â§ÑÁêÜÂçïÂº†ÂõæÂÉè
            print(f"\nüñºÔ∏è ÂçïÂõæÂÉèÂ§ÑÁêÜÊ®°Âºè")
            print(f"ÂõæÂÉèË∑ØÂæÑ: {args.image_path}")
            
            start_time = time.time()
            vector = vectorizer.vectorize_image(args.image_path)
            end_time = time.time()
            
            processing_time = end_time - start_time
            
            print("\n" + "=" * 50)
            print("üéâ ÂêëÈáèÂåñÂÆåÊàê!")
            print("-" * 30)
            print(f"ËÆæÂ§á: {vectorizer.device}")
            print(f"Ê®°Âûã: {args.model}")
            print(f"Â§ÑÁêÜÊó∂Èó¥: {processing_time:.4f} Áßí")
            print(f"ÁâπÂæÅÂêëÈáèÂΩ¢Áä∂: {vector.shape}")
            print(f"Ââç10‰∏™ÂÖÉÁ¥†: {vector[:10]}")
            print(f"ÁªüËÆ°‰ø°ÊÅØ: ÂùáÂÄº={vector.mean():.4f}, Ê†áÂáÜÂ∑Æ={vector.std():.4f}")

        else:
            print(f"‚ùå ÈîôËØØ: Ë∑ØÂæÑ '{args.image_path}' ‰∏çÊòØÊúâÊïàÁöÑÊñá‰ª∂ÊàñÁõÆÂΩï")

    except KeyboardInterrupt:
        print("\n‚ö° Áî®Êà∑‰∏≠Êñ≠Êìç‰Ωú")
    except Exception as e:
        print(f"\n‚ùå ÂèëÁîüÈîôËØØ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()